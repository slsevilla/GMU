library(dada2); packageVersion("dada2")
# Filename parsing
path <- "C:\Users\sevillas2\Google Drive\My Documents\Education\George Mason University\BINF703\2018_Spring_BaranovaGillevet\Analysis\DADA2"
library(dada2); packageVersion("dada2")
# Filename parsing
path <- file.path("C:Users\sevillas2\Google Drive\My Documents\Education\George Mason University\BINF703\2018_Spring_BaranovaGillevet\Analysis\DADA2")
library(dada2); packageVersion("dada2")
# Filename parsing
path <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2"
filtpath <- file.path(path, "filtered") # Filtered files go into the filtered/ subdirectory
fns <- list.files(path, pattern=".fastq") # CHANGE if different file extensions
# Filtering
filterAndTrim(file.path(path,fns), file.path(filtpath,fns),
truncLen=240, maxEE=1, truncQ=11, rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered_run1"
filts <- list.files(filtpath, pattern="073.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered"
filts <- list.files(filtpath, pattern="073.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
cat("Processing:", sam, "/n")
derep <- derepFastq(filts[[sam]])
dds[[sam]] <- dada(derep, err=err, multithread=TRUE)
}
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/seqtab073.rds")
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered"
filts <- list.files(filtpath, pattern="074.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
cat("Processing:", sam, "\n")
derep <- derepFastq(filts[[sam]])
dds[[sam]] <- dada(derep, err=err, multithread=TRUE)
}
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/seqtab074.rds")
library(dada2); packageVersion("dada2")
# Merge multiple runs (if necessary)
st1 <- readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/seqtab073.rds")
st2 <- readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/seqtab074.rds")
st.all <- mergeSequenceTables(st1, st2)
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered"
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered"
filts <- list.files(filtpath, pattern="074.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
names
names(filts)
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered"
filts <- list.files(filtpath, pattern="074.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
names(filts)
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered"
filts <- list.files(filtpath, pattern="073.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
names(filts)
library(dada2); packageVersion("dada2")
# Filename parsing
path <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2"
filtpath <- file.path(path, "filtered") # Filtered files go into the filtered/ subdirectory
fns <- list.files(path, pattern=".fastq") # CHANGE if different file extensions
# Filtering
filterAndTrim(file.path(path,fns), file.path(filtpath,fns),
truncLen=240, maxEE=1, truncQ=11, rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered"
filts <- list.files(filtpath, pattern="073.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
cat("Processing:", sam, "/n")
derep <- derepFastq(filts[[sam]])
dds[[sam]] <- dada(derep, err=err, multithread=TRUE)
}
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/seqtab073.rds")
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/filtered"
filts <- list.files(filtpath, pattern="074.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
cat("Processing:", sam, "\n")
derep <- derepFastq(filts[[sam]])
dds[[sam]] <- dada(derep, err=err, multithread=TRUE)
}
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/seqtab074.rds")
library(dada2); packageVersion("dada2")
# Merge multiple runs (if necessary)
st1 <- readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/seqtab073.rds")
st2 <- readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/seqtab074.rds")
st.all <- mergeSequenceTables(st1, st2)
# Remove chimeras
seqtab <- removeBimeraDenovo(st.all, method="consensus", multithread=TRUE)
# Assign taxonomy
tax <- assignTaxonomy(seqtab, "/path/to/silva_nr_v128_train_set.fa.gz", multithread=TRUE)
library(dada2); packageVersion("dada2")
# Filename parsing
path <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Samples"
filtpath <- file.path(path, "filtered") # Filtered files go into the filtered/ subdirectory
fns <- list.files(path, pattern=".fastq") # CHANGE if different file extensions
# Filtering
filterAndTrim(file.path(path,fns), file.path(filtpath,fns),
truncLen=240, maxEE=1, truncQ=11, rm.phix=TRUE,
compress=TRUE, verbose=TRUE, multithread=TRUE)
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Samples/filtered"
filts <- list.files(filtpath, pattern="073.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
cat("Processing:", sam, "/n")
derep <- derepFastq(filts[[sam]])
dds[[sam]] <- dada(derep, err=err, multithread=TRUE)
}
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab073.rds")
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab073.rds")
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Samples/filtered"
filts <- list.files(filtpath, pattern="074.fastq", full.names=TRUE)
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1)
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
cat("Processing:", sam, "\n")
derep <- derepFastq(filts[[sam]])
dds[[sam]] <- dada(derep, err=err, multithread=TRUE)
}
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab074.rds")
library(dada2); packageVersion("dada2")
# Merge multiple runs (if necessary)
st1 <- readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab073.rds")
st2 <- readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab074.rds")
st.all <- mergeSequenceTables(st1, st2)
# Remove chimeras
seqtab <- removeBimeraDenovo(st.all, method="consensus", multithread=TRUE)
# Assign taxonomy
tax <- assignTaxonomy(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/References", multithread=TRUE)
# Write to disk
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab_final.rds")
saveRDS(tax, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/tax_final.rds")
save.image("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/Code/RData_Meals/.RData")
seqs <- getSequences(seqtab)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)
library(AlignSeq)
source("http://bioconductor.org/biocLite.R")
biocLite(AlignSeq)
source("http://bioconductor.org/biocLite.R")
boicLite(AlignSeq)
boicLite(AlignSeqs)
biocLite(AlignSeqs)
library("knitr")
library("BiocStyle")
install.packages("BiocStyle")
install.packages("knitr")
library("knitr")
library("BiocStyle")
install.packages(BiocStyle)
library("knitr")
#library("BiocStyle")
library(dada2); packageVersion("dada2")
.cran_packages <- c("ggplot2", "gridExtra")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
source("http://bioconductor.org/biocLite.R")
biocLite(.bioc_packages[!.inst], ask = F)
}sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
library("knitr")
#library("BiocStyle")
library(dada2); packageVersion("dada2")
.cran_packages <- c("ggplot2", "gridExtra")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
source("http://bioconductor.org/biocLite.R")
biocLite(.bioc_packages[!.inst], ask = F)
}
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
opts_chunk$set(cache = FALSE,fig.path="dadafigure/")
read_chunk(file.path("src", "bioinformatics.R"))
seqs <- getSequences(seqtab)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
install.packages("phangorn")
library(phangorn)
install.packages(ape)
install.packages("ape")
library(ape)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
library(phyloseq)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
install.packages(phyDat)
install.packages("phyDat")
install.packages("phyDat",force(TRUE))
library(phangorn)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phang.align)
fit = pml(treeNJ, data=phang.align)
## negative edges length changed to
0!
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
rearrangement = "stochastic", control = pml.control(trace = 0))
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
mimarks_path <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/MIMARKS_Data_combined.csv"
samdf <- read.csv(mimarks_path, header=TRUE)
save.image("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/Code/RData_Meals/.RData")
