---
title: "Meal Worms"
output: html_notebook
---
Install packages and load librarys
```{r}
.cran_packages <- c("ggplot2", "gridExtra")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
   source("http://bioconductor.org/biocLite.R")
   biocLite(.bioc_packages[!.inst], ask = F)
}
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)

library("knitr")
library(dada2); packageVersion("dada2")
library(phangorn)
libray(phyloseq)
opts_chunk$set(cache = FALSE,fig.path="dadafigure/")
```

Perform Filtering of data
```{r}
# Filename parsing
path <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Samples"
filtpath <- file.path(path, "filtered") # Filtered files go into the filtered/ subdirectory
fns <- list.files(path, pattern=".fastq") # CHANGE if different file extensions
# Filtering
filterAndTrim(file.path(path,fns), file.path(filtpath,fns), 
              truncLen=240, maxEE=1, truncQ=11, rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
```

Construct Matrix for Run 1
```{r}
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Samples/filtered"
filts <- list.files(filtpath, pattern="073.fastq", full.names=TRUE) 
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1) 
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
  cat("Processing:", sam, "/n")
  derep <- derepFastq(filts[[sam]])
  dds[[sam]] <- dada(derep, err=err, multithread=TRUE)
}
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab073.rds") 
```

Construct Matrix for Run 2
```{r}
library(dada2); packageVersion("dada2")
# File parsing
filtpath <- "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Samples/filtered"
filts <- list.files(filtpath, pattern="074.fastq", full.names=TRUE) 
sample.names <- sapply(strsplit(basename(filts), "_"), `[`, 1) 
names(filts) <- sample.names
# Learn error rates
set.seed(100)
err <- learnErrors(filts, nreads = 1e6, multithread=TRUE, randomize=TRUE)
# Infer sequence variants
dds <- vector("list", length(sample.names))
names(dds) <- sample.names
for(sam in sample.names) {
  cat("Processing:", sam, "\n")
  derep <- derepFastq(filts[[sam]])
  dds[[sam]] <- dada(derep, err=err, multithread=TRUE)
}
# Construct sequence table and write to disk
seqtab <- makeSequenceTable(dds)
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab074.rds") 
```

Chimeras and Taxonomy - Merge both runs
```{r}
library(dada2); packageVersion("dada2")
# Merge multiple runs (if necessary)
st1 <- readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab073.rds")
st2 <- readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab074.rds")
st.all <- mergeSequenceTables(st1, st2)
# Remove chimeras
seqtab <- removeBimeraDenovo(st.all, method="consensus", multithread=TRUE)
# Assign taxonomy
taxtab <- assignTaxonomy(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/References", multithread=TRUE)
# Write to disk
saveRDS(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/seqtab_final.rds") 
saveRDS(tax, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/tax_final.rds")
```

Construct Phylo Tree
```{r}
library(phyloseq)
library(phangorn)
seqs <- getSequences(seqtab)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)

phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phang.align)

fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
                      rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
```

Create PhyloSeq Object
```{r}
mimarks_path <- file.path("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Input_PhyloSeq.csv")
samdf <- read.csv(mimarks_path, header=TRUE)
all(rownames(seqtab) %in% samdf$SampleID) # Verificattion - TRUE

rownames(samdf) <- samdf$SampleID
samdf <- samdf[rownames(seqtab), ]
ps <- phyloseq(tax_table(taxtab),
                 sample_data(samdf),
                 otu_table(seqtab, taxa_are_rows = FALSE),
                 phy_tree(fitGTR$tree))
saveRDS(ps, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/ps_final.rds")
```

Load Phylo Data
```{r}
library("phyloseq")
library("gridExtra")
ps = readRDS("C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/Output/ps_final.rds")
```
Run Analysis in PhyloSeq
```{r}
plot_bar(ps, fill="Phylum")
```

